{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# import src.data.data as data\n",
    "import src.data.config as cfg\n",
    "import src.interactive.functions as interactive\n",
    "\n",
    "import json\n",
    "import random\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string With Punctuation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"string. With. Punctuation?\" # Sample string \n",
    "s.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "stop_words = set(stopwords.words('english')) \n",
    "word_tokens = word_tokenize(example_sent) \n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMP_FILE = '../../data/personachat_self_original_comet.json'\n",
    "DUMP_FILE = '../../data/personachat_self_original_comet_validation.json'  # ** VALIDATION SPLIT ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dump_fname):\n",
    "    annotated_data = json.load(open(dump_fname,'r'))\n",
    "    return annotated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data = load_data(DUMP_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['valid'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000, dict_keys(['personality', 'utterances', 'coment_annotation']))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotated_data), len(annotated_data[split]), annotated_data[split][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotated_data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sent': 'i read twenty books a year .',\n",
       "  'comet': {'oEffect': {'event': 'i read twenty books a year .',\n",
       "    'effect_type': 'oEffect',\n",
       "    'beams': ['none',\n",
       "     'they get a good grade',\n",
       "     'wants to read more',\n",
       "     'they learn about the books',\n",
       "     'they learn about the book']},\n",
       "   'oReact': {'event': 'i read twenty books a year .',\n",
       "    'effect_type': 'oReact',\n",
       "    'beams': ['none', 'happy', 'interested', 'impressed', 'proud']},\n",
       "   'oWant': {'event': 'i read twenty books a year .',\n",
       "    'effect_type': 'oWant',\n",
       "    'beams': ['none',\n",
       "     'to teach them more',\n",
       "     'to read more books',\n",
       "     'to read more',\n",
       "     'to teach them']},\n",
       "   'xAttr': {'event': 'i read twenty books a year .',\n",
       "    'effect_type': 'xAttr',\n",
       "    'beams': ['intelligent', 'studious', 'intellectual', 'smart', 'educated']},\n",
       "   'xEffect': {'event': 'i read twenty books a year .',\n",
       "    'effect_type': 'xEffect',\n",
       "    'beams': ['gains knowledge',\n",
       "     'learns a lot',\n",
       "     'learns something new',\n",
       "     'none',\n",
       "     'learns something']},\n",
       "   'xIntent': {'event': 'i read twenty books a year .',\n",
       "    'effect_type': 'xIntent',\n",
       "    'beams': ['to learn',\n",
       "     'to learn something new',\n",
       "     'to learn a lot',\n",
       "     'to learn something',\n",
       "     'to learn more']},\n",
       "   'xNeed': {'event': 'i read twenty books a year .',\n",
       "    'effect_type': 'xNeed',\n",
       "    'beams': ['none',\n",
       "     'to go to the library',\n",
       "     'to buy books',\n",
       "     'to go to school',\n",
       "     'to have books']},\n",
       "   'xReact': {'event': 'i read twenty books a year .',\n",
       "    'effect_type': 'xReact',\n",
       "    'beams': ['smart', 'smarter', 'intelligent', 'educated', 'happy']},\n",
       "   'xWant': {'event': 'i read twenty books a year .',\n",
       "    'effect_type': 'xWant',\n",
       "    'beams': ['to get a good grade',\n",
       "     'to learn something new',\n",
       "     'to learn more',\n",
       "     'to read more',\n",
       "     'to get a good job']}}},\n",
       " {'sent': \"i'm a stunt double as my second job .\",\n",
       "  'comet': {'oEffect': {'event': \"i'm a stunt double as my second job .\",\n",
       "    'effect_type': 'oEffect',\n",
       "    'beams': ['none',\n",
       "     \"get 's things done well\",\n",
       "     \"get 's their work done\",\n",
       "     \"get 's things done\",\n",
       "     'gets fired']},\n",
       "   'oReact': {'event': \"i'm a stunt double as my second job .\",\n",
       "    'effect_type': 'oReact',\n",
       "    'beams': ['none', 'annoyed', 'angry', 'irritated', 'upset']},\n",
       "   'oWant': {'event': \"i'm a stunt double as my second job .\",\n",
       "    'effect_type': 'oWant',\n",
       "    'beams': ['none',\n",
       "     'to get rid of him',\n",
       "     'to fire personx',\n",
       "     'to thank personx',\n",
       "     'to hire me']},\n",
       "   'xAttr': {'event': \"i'm a stunt double as my second job .\",\n",
       "    'effect_type': 'xAttr',\n",
       "    'beams': ['untrustworthy',\n",
       "     'mean',\n",
       "     'immature',\n",
       "     'incompetent',\n",
       "     'irresponsible']},\n",
       "   'xEffect': {'event': \"i'm a stunt double as my second job .\",\n",
       "    'effect_type': 'xEffect',\n",
       "    'beams': ['none',\n",
       "     'gets yelled at',\n",
       "     'gets fired',\n",
       "     'personx gets a promotion',\n",
       "     'personx gets fired']},\n",
       "   'xIntent': {'event': \"i'm a stunt double as my second job .\",\n",
       "    'effect_type': 'xIntent',\n",
       "    'beams': ['none',\n",
       "     'to be the best',\n",
       "     'to be a clown',\n",
       "     'to be the boss',\n",
       "     'to make money']},\n",
       "   'xNeed': {'event': \"i'm a stunt double as my second job .\",\n",
       "    'effect_type': 'xNeed',\n",
       "    'beams': ['none',\n",
       "     'to be in a position of power',\n",
       "     'to have a job',\n",
       "     'to have a reason to do it',\n",
       "     'to be a stunt driver']},\n",
       "   'xReact': {'event': \"i'm a stunt double as my second job .\",\n",
       "    'effect_type': 'xReact',\n",
       "    'beams': ['satisfied', 'happy', 'ashamed', 'guilty', 'proud']},\n",
       "   'xWant': {'event': \"i'm a stunt double as my second job .\",\n",
       "    'effect_type': 'xWant',\n",
       "    'beams': ['to get a new job',\n",
       "     'to get a raise',\n",
       "     'to get a promotion',\n",
       "     'to be successful',\n",
       "     'to prove his skills']}}},\n",
       " {'sent': 'i only eat kosher .',\n",
       "  'comet': {'oEffect': {'event': 'i only eat kosher .',\n",
       "    'effect_type': 'oEffect',\n",
       "    'beams': ['none',\n",
       "     'they eat it too',\n",
       "     'no effect',\n",
       "     'they get sick',\n",
       "     'they eat it']},\n",
       "   'oReact': {'event': 'i only eat kosher .',\n",
       "    'effect_type': 'oReact',\n",
       "    'beams': ['none', 'happy', 'hungry', 'satisfied', 'disgusted']},\n",
       "   'oWant': {'event': 'i only eat kosher .',\n",
       "    'effect_type': 'oWant',\n",
       "    'beams': ['none',\n",
       "     'to eat something else',\n",
       "     'to eat it too',\n",
       "     'to eat some too',\n",
       "     'to eat something else too']},\n",
       "   'xAttr': {'event': 'i only eat kosher .',\n",
       "    'effect_type': 'xAttr',\n",
       "    'beams': ['hungry', 'satiated', 'fat', 'vegan', 'healthy']},\n",
       "   'xEffect': {'event': 'i only eat kosher .',\n",
       "    'effect_type': 'xEffect',\n",
       "    'beams': ['becomes full',\n",
       "     'gets sick',\n",
       "     'personx is full',\n",
       "     'none',\n",
       "     'is full']},\n",
       "   'xIntent': {'event': 'i only eat kosher .',\n",
       "    'effect_type': 'xIntent',\n",
       "    'beams': ['to be healthy',\n",
       "     'to not be hungry',\n",
       "     'to be full',\n",
       "     'none',\n",
       "     'to not eat']},\n",
       "   'xNeed': {'event': 'i only eat kosher .',\n",
       "    'effect_type': 'xNeed',\n",
       "    'beams': ['none',\n",
       "     'to go to the store',\n",
       "     'to go to the grocery store',\n",
       "     'to go to the market',\n",
       "     'to buy it']},\n",
       "   'xReact': {'event': 'i only eat kosher .',\n",
       "    'effect_type': 'xReact',\n",
       "    'beams': ['satisfied', 'full', 'satiated', 'healthy', 'happy']},\n",
       "   'xWant': {'event': 'i only eat kosher .',\n",
       "    'effect_type': 'xWant',\n",
       "    'beams': ['to eat something else',\n",
       "     'to be full',\n",
       "     'to drink water',\n",
       "     'to be healthy',\n",
       "     'to have a drink']}}},\n",
       " {'sent': 'i was raised in a single parent household .',\n",
       "  'comet': {'oEffect': {'event': 'i was raised in a single parent household .',\n",
       "    'effect_type': 'oEffect',\n",
       "    'beams': ['none',\n",
       "     'they are taken care of by their parent',\n",
       "     'they are taken care of',\n",
       "     'they raise their own children',\n",
       "     'they raise their own kids']},\n",
       "   'oReact': {'event': 'i was raised in a single parent household .',\n",
       "    'effect_type': 'oReact',\n",
       "    'beams': ['none', 'sad', 'happy', 'worried', 'loved']},\n",
       "   'oWant': {'event': 'i was raised in a single parent household .',\n",
       "    'effect_type': 'oWant',\n",
       "    'beams': ['none',\n",
       "     'to support personx',\n",
       "     'to help personx raise their child',\n",
       "     'to help personx',\n",
       "     'to support him']},\n",
       "   'xAttr': {'event': 'i was raised in a single parent household .',\n",
       "    'effect_type': 'xAttr',\n",
       "    'beams': ['alone', 'sad', 'lonely', 'independent', 'young']},\n",
       "   'xEffect': {'event': 'i was raised in a single parent household .',\n",
       "    'effect_type': 'xEffect',\n",
       "    'beams': ['none',\n",
       "     'personx has a lot of responsibility',\n",
       "     'personx has a baby .',\n",
       "     'personx has a baby',\n",
       "     'personx has a child']},\n",
       "   'xIntent': {'event': 'i was raised in a single parent household .',\n",
       "    'effect_type': 'xIntent',\n",
       "    'beams': ['none',\n",
       "     'to be alone',\n",
       "     'to raise a child',\n",
       "     'to be a good parent',\n",
       "     'to be a good child']},\n",
       "   'xNeed': {'event': 'i was raised in a single parent household .',\n",
       "    'effect_type': 'xNeed',\n",
       "    'beams': ['none',\n",
       "     'to have a parent',\n",
       "     'to have a baby',\n",
       "     'to have a child',\n",
       "     'to have a baby .']},\n",
       "   'xReact': {'event': 'i was raised in a single parent household .',\n",
       "    'effect_type': 'xReact',\n",
       "    'beams': ['sad', 'lonely', 'happy', 'worried', 'alone']},\n",
       "   'xWant': {'event': 'i was raised in a single parent household .',\n",
       "    'effect_type': 'xWant',\n",
       "    'beams': ['to raise a child',\n",
       "     'to raise their own children',\n",
       "     'to raise their own kids',\n",
       "     'to raise a baby',\n",
       "     'to raise their child']}}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data[split][0]['coment_annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " {'candidates': ['oh really ? i am actually in high school and i am graduating as class of 2019 !',\n",
       "   \"that's an interesting choice . i'd have to pick french fries\",\n",
       "   'i just got a pet fish for my 18th birthday yesterday from my parents .',\n",
       "   'yeah , well what about you ?',\n",
       "   'my favorite watch is the rolex ? what is yours ?',\n",
       "   \"what is in spain that's so interesting\",\n",
       "   \"i don't like clowns . they are scary to a kid like me\",\n",
       "   'poetry . roses are red . violet are . . . ?',\n",
       "   'my father is a member of the army , served for 10 years now .',\n",
       "   'oh i like mexican food , but my favorite food are cheeseburgers',\n",
       "   'hey there , are you a mother ?',\n",
       "   \"it sure is . i'd like to see more of the city though .\",\n",
       "   'it is not so fun i have 2 friend who speak a different langues',\n",
       "   \"i'd like some honey though . do you sell it ?\",\n",
       "   'i am a recovering heavy drinker . full time . how about you ?',\n",
       "   'hi ! i have three kids . how many do you have ?',\n",
       "   'awesome ! i own 2 dogs , love them',\n",
       "   'yes , my favorite is broccoli and tofu in a garlic sauce . yum !',\n",
       "   'maybe he can skydive to see a better view',\n",
       "   'i am good , i just got off work and tired , i have two jobs .'],\n",
       "  'history': ['hello what are doing today ?']})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotated_data[split][0]['utterances']), annotated_data[split][0]['utterances'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidates': ['why have you not sent help ? ! the scorpions are stinging my legs ! ree ! ! ! ! ! ! !',\n",
       "  'that is great i am expecting twins in two months . will these be your first kids ?',\n",
       "  'do you live on a farm or ranch ?',\n",
       "  'hi how are you doing tonight i am fine .',\n",
       "  \"i'd love to see her do that .\",\n",
       "  \"i don't . but i am so glad you do something that brings you joy\",\n",
       "  'it is hard , buy my dog keeps me company . do you have dogs ?',\n",
       "  'sounds like a good plan , what would you like to teach ?',\n",
       "  'i like rap music and i also produce for music artists .',\n",
       "  'where do you work ?',\n",
       "  'i broke my arm so i can not drink coffee',\n",
       "  \"i meant mickey . cool i've a lot of friends and love the playground . do you ?\",\n",
       "  'oh , yes . i wish i could skate to school . i ride the bus instead .',\n",
       "  'that is my idea of heaven . i love bunnies ! i donate to a bunny charity too .',\n",
       "  'i work on a freelance basis as an author , blogger and affiliate marketer . and you ?',\n",
       "  'like me ? would you go on vacation to the beach with me',\n",
       "  \"i don't let myself watch tv\",\n",
       "  'we can go for a trade that sounds awesome',\n",
       "  'what part of the world is bratislava ?',\n",
       "  \"i rather read , i've read about 20 books this year .\"],\n",
       " 'history': ['hello what are doing today ?',\n",
       "  'i am good , i just got off work and tired , i have two jobs .',\n",
       "  'i just got done watching a horror movie']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data[split][0]['utterances'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidates': ['fun , i should take my kids out to do that . do you have a family ?',\n",
       "  'they were popular in my younger days lol',\n",
       "  'i sing and love rock especially while working . keeps me pumped .',\n",
       "  'i mean where i come from kitties do not play with birds .',\n",
       "  'i tend my rose garden and read books . i am deaf in one ear',\n",
       "  'you can learn to say something nice and smart',\n",
       "  'when in europe all i do is shop',\n",
       "  'wow , that is exciting ! i never went to a nascar race .',\n",
       "  'i live in hawaii and i work from home .',\n",
       "  'hello jennifer , i am a proud dad and husband',\n",
       "  'and my spouse used all the money i earned',\n",
       "  'oh young people . the holidays are coming . that makes me sad .',\n",
       "  'i had surgery last week and now i think of an object , and it moves !',\n",
       "  'hello ! i just got back from a run . what are you up to today ?',\n",
       "  'hello , my name is ally and my favourite color is orange',\n",
       "  \"no i didn't see that . i am excited for the new star wars though\",\n",
       "  'that is exciting ! do you go to church ?',\n",
       "  'bless her ! no kids here . more of a dog man .',\n",
       "  \"i've one dog and a nice career\",\n",
       "  'now that i am older home depot is my toy r us .'],\n",
       " 'history': ['hello what are doing today ?',\n",
       "  'i am good , i just got off work and tired , i have two jobs .',\n",
       "  'i just got done watching a horror movie',\n",
       "  \"i rather read , i've read about 20 books this year .\",\n",
       "  'wow ! i do love a good horror movie . loving this cooler weather',\n",
       "  'but a good movie is always good .',\n",
       "  'yes ! my son is in junior high and i just started letting him watch them too',\n",
       "  'i work in the movies as well .',\n",
       "  'neat ! ! i used to work in the human services field',\n",
       "  'yes it is neat , i stunt double , it is so much fun and hard work .',\n",
       "  'yes i bet you can get hurt . my wife works and i stay at home',\n",
       "  'nice , i only have one parent so now i help out my mom .',\n",
       "  'i bet she appreciates that very much .',\n",
       "  'she raised me right , i am just like her .',\n",
       "  'my dad was always busy working at home depot']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data[split][0]['utterances'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(s):\n",
    "    s = s.lower()\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "    word_tokens = word_tokenize(s) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return filtered_sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(item):\n",
    "    \n",
    "    utterances = item['utterances']\n",
    "    history = utterances[-1]['history']\n",
    "    all_conversation_words = []\n",
    "    for h in history:\n",
    "        #print(\"history: \", h)\n",
    "        all_conversation_words.extend(process_text(h))\n",
    "    all_conversation_words = set(all_conversation_words)\n",
    "\n",
    "    personality = item['personality']\n",
    "    all_personality_words = []\n",
    "    for h in personality:\n",
    "        #print(\"personality: \", h)\n",
    "        all_personality_words.extend(process_text(h))\n",
    "    all_personality_words = set(all_personality_words)\n",
    "    \n",
    "    coment_annotation = item['coment_annotation']\n",
    "    all_comet_words = []\n",
    "    for h in coment_annotation:\n",
    "        comet = h['comet']\n",
    "        for _,value in comet.items():\n",
    "            for sent in value['beams']:\n",
    "                #print('coment_annotation: ',sent)\n",
    "                if sent.strip() == 'none':\n",
    "                    continue\n",
    "                all_comet_words.extend(process_text(sent))\n",
    "    all_comet_words = set(all_comet_words)\n",
    "    \n",
    "    \n",
    "    conv_personality_overlap = len(all_conversation_words.intersection(all_personality_words)) / ( len(all_conversation_words) )\n",
    "    conv_comet_overlap = len(all_conversation_words.intersection(all_comet_words)) /  ( len(all_conversation_words) )\n",
    "    \n",
    "    all_extended_personality_words = all_comet_words.union(all_personality_words)\n",
    "    conv_ext_personality_overlap = len(all_conversation_words.intersection(all_extended_personality_words)) /  ( len(all_conversation_words) )\n",
    "    \n",
    "    additional_word_set = all_conversation_words.intersection(all_comet_words) - all_conversation_words.intersection(all_personality_words)\n",
    "    \n",
    "    #print(\"additional_word_set = \", additional_word_set)\n",
    "    #print(conv_personality_overlap, conv_comet_overlap)\n",
    "    \n",
    "    return {'additional_word_set':additional_word_set, \n",
    "            'conv_personality_overlap':conv_personality_overlap,\n",
    "            'conv_comet_overlap':conv_comet_overlap,\n",
    "            'additional_recall':conv_ext_personality_overlap - conv_personality_overlap}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additional_word_set': {'done', 'get', 'good', 'help', 'well', 'work'},\n",
       " 'conv_personality_overlap': 0.1111111111111111,\n",
       " 'conv_comet_overlap': 0.15873015873015872,\n",
       " 'additional_recall': 0.09523809523809523}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process(annotated_data[split][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ret_split = []\n",
    "for datum in annotated_data[split]:\n",
    "    all_ret_split.append(process(datum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_ret_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_recall_vals_split = [val['additional_recall'] for val in all_ret_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.describe(additional_recall_vals_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(additional_recall_vals_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
